{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Signal Generator - Training Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline for:\n",
    "1. Downloading market data\n",
    "2. Engineering features\n",
    "3. Training ML models\n",
    "4. Generating trading signals\n",
    "5. Backtesting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded environment variables from .env\n",
      "Project root: c:\\Users\\Admin\\Documents\\Projects\\ml-signal-generator\n",
      "Output directory: c:\\Users\\Admin\\Documents\\Projects\\ml-signal-generator\\outputs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get the project root directory (parent of notebooks directory)\n",
    "current_dir = Path(os.getcwd())\n",
    "if current_dir.name == 'notebooks':\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    # If running from project root, notebooks should be in notebooks/ subdirectory\n",
    "    project_root = current_dir\n",
    "\n",
    "# Load environment variables from .env file\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"✓ Loaded environment variables from .env\")\n",
    "else:\n",
    "    print(f\"⚠️  No .env file found. Using defaults. Create .env from .env.example if needed.\")\n",
    "\n",
    "# Add src to path\n",
    "src_path = project_root / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Set output directory\n",
    "output_dir = project_root / 'outputs'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display  # For better DataFrame display in Jupyter\n",
    "\n",
    "from features import download_data, engineer_features, prepare_features_for_training\n",
    "from model import time_series_split, train_random_forest, train_xgboost, get_feature_importance, evaluate_model\n",
    "from backtest import generate_signals, backtest_strategy, plot_equity_curve, plot_feature_importance\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Source: alpha_vantage\n",
      "API Key: ************4O8F\n",
      "Loading saved data from SPY_2020-01-01_2024-01-01.csv...\n",
      "✓ Loaded 1006 days of saved data\n",
      "Date range: 2020-01-02 00:00:00 to 2023-12-29 00:00:00\n",
      "\n",
      "✓ Successfully loaded 1006 days of data\n",
      "Date range: 2020-01-02 00:00:00 to 2023-12-29 00:00:00\n",
      "\n",
      "Data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>323.54</td>\n",
       "      <td>324.89</td>\n",
       "      <td>322.53</td>\n",
       "      <td>324.87</td>\n",
       "      <td>59037072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>321.16</td>\n",
       "      <td>323.64</td>\n",
       "      <td>321.10</td>\n",
       "      <td>322.41</td>\n",
       "      <td>77708081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>320.49</td>\n",
       "      <td>323.73</td>\n",
       "      <td>320.36</td>\n",
       "      <td>323.64</td>\n",
       "      <td>55596982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>323.02</td>\n",
       "      <td>323.54</td>\n",
       "      <td>322.24</td>\n",
       "      <td>322.73</td>\n",
       "      <td>40461249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>322.94</td>\n",
       "      <td>325.78</td>\n",
       "      <td>322.67</td>\n",
       "      <td>324.45</td>\n",
       "      <td>68177241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Volume\n",
       "Date                                                \n",
       "2020-01-02  323.54  324.89  322.53  324.87  59037072\n",
       "2020-01-03  321.16  323.64  321.10  322.41  77708081\n",
       "2020-01-06  320.49  323.73  320.36  323.64  55596982\n",
       "2020-01-07  323.02  323.54  322.24  322.73  40461249\n",
       "2020-01-08  322.94  325.78  322.67  324.45  68177241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "TICKER = 'SPY'  # S&P 500 ETF\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2024-01-01'\n",
    "\n",
    "# API Configuration (loads from .env file, with fallback to defaults)\n",
    "# Options: 'yfinance' (default, free but rate limited), 'alpha_vantage' (free with API key)\n",
    "# NOTE: If Alpha Vantage gives errors, you can override here: API_SOURCE = 'yfinance'\n",
    "API_SOURCE = os.getenv('API_SOURCE', 'yfinance')  # Load from .env or use default\n",
    "\n",
    "# Get API key from .env based on source\n",
    "if API_SOURCE == 'alpha_vantage':\n",
    "    API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "else:\n",
    "    API_KEY = None  # yfinance doesn't need an API key\n",
    "\n",
    "# Display API configuration\n",
    "print(f\"API Source: {API_SOURCE}\")\n",
    "if API_KEY:\n",
    "    print(f\"API Key: {'*' * (len(API_KEY) - 4) + API_KEY[-4:]}\")  # Show only last 4 chars\n",
    "else:\n",
    "    print(\"API Key: Not set (using yfinance or not required)\")\n",
    "    if API_SOURCE == 'alpha_vantage':\n",
    "        print(f\"⚠️  WARNING: {API_SOURCE} requires an API key but none was found!\")\n",
    "        print(\"   Either add API key to .env or set API_SOURCE='yfinance'\")\n",
    "\n",
    "# Quick fix: If Alpha Vantage fails, uncomment the line below to force yfinance:\n",
    "# API_SOURCE = 'yfinance'\n",
    "\n",
    "# Instructions for setting up .env:\n",
    "# 1. Copy .env.example to .env: cp .env.example .env\n",
    "# 2. Edit .env and add your API keys\n",
    "# 3. Get free API keys:\n",
    "#    - Alpha Vantage: https://www.alphavantage.co/support/#api-key\n",
    "\n",
    "# OPTION: Set to True to skip download and use sample data (for testing when rate limited)\n",
    "USE_SAMPLE_DATA = False  # Set to True if you're rate limited and want to continue\n",
    "\n",
    "# Try to load from saved file first (checks both CSV and Excel)\n",
    "data_file_csv = project_root / 'data' / f'{TICKER}_{START_DATE}_{END_DATE}.csv'\n",
    "data_file_xlsx = project_root / 'data' / f'{TICKER}_{START_DATE}_{END_DATE}.xlsx'\n",
    "data = None\n",
    "\n",
    "# Check for CSV first, then Excel\n",
    "if data_file_csv.exists():\n",
    "    print(f\"Loading saved data from {data_file_csv.name}...\")\n",
    "    try:\n",
    "        data = pd.read_csv(data_file_csv, index_col=0, parse_dates=True)\n",
    "        print(f\"✓ Loaded {len(data)} days of saved data from CSV\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error loading CSV: {e}\")\n",
    "        data = None\n",
    "elif data_file_xlsx.exists():\n",
    "    print(f\"Loading saved data from {data_file_xlsx.name}...\")\n",
    "    try:\n",
    "        data = pd.read_excel(data_file_xlsx, index_col=0, parse_dates=True)\n",
    "        print(f\"✓ Loaded {len(data)} days of saved data from Excel\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error loading Excel: {e}\")\n",
    "        data = None\n",
    "\n",
    "# If no saved data, try to download\n",
    "if data is None or data.empty:\n",
    "    print(f\"\\nDownloading data for {TICKER}...\")\n",
    "    import time\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_delay = 30  # seconds - increased to 30 seconds between retries\n",
    "    initial_wait = 60  # Wait 60 seconds before first attempt if recently rate limited\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        # Wait before first attempt if this is a retry (not the first attempt)\n",
    "        if attempt > 0:\n",
    "            wait_time = retry_delay * attempt\n",
    "            print(f\"Waiting {wait_time} seconds before retry attempt {attempt + 1}/{max_retries}...\")\n",
    "            time.sleep(wait_time)\n",
    "        \n",
    "        try:\n",
    "            data = download_data(TICKER, START_DATE, END_DATE, api_source=API_SOURCE, api_key=API_KEY)\n",
    "            \n",
    "            # Check if download was successful\n",
    "            if data.empty or len(data) == 0:\n",
    "                if attempt < max_retries - 1:\n",
    "                    # Will wait at start of next loop iteration\n",
    "                    print(f\"Download returned empty data. Will retry... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise ValueError(f\"Failed to download data for {TICKER} after {max_retries} attempts.\")\n",
    "            \n",
    "            # Save data for future use\n",
    "            data_dir = project_root / 'data'\n",
    "            data_dir.mkdir(exist_ok=True)\n",
    "            data.to_csv(data_file)\n",
    "            print(f\"✓ Data saved to {data_file.name} for future use\")\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            error_type = type(e).__name__\n",
    "            \n",
    "            # Check for rate limit errors (both in message and exception type)\n",
    "            is_rate_limit = (\n",
    "                'rate limit' in error_msg or \n",
    "                'too many requests' in error_msg or\n",
    "                'YFRateLimitError' in error_type or\n",
    "                'ratelimit' in error_msg\n",
    "            )\n",
    "            \n",
    "            if is_rate_limit:\n",
    "                if attempt < max_retries - 1:\n",
    "                    # Will wait at start of next loop iteration\n",
    "                    print(f\"Rate limit hit. Will retry with longer wait... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"\\n❌ Rate limited after {max_retries} attempts.\")\n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(\"YAHOO FINANCE RATE LIMIT - SOLUTIONS:\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(\"1. Wait 15-20 minutes, then run this cell again\")\n",
    "                    print(\"2. Try again later today (rate limits reset over time)\")\n",
    "                    print(\"3. Once data downloads successfully, it will be saved\")\n",
    "                    print(\"   and you won't need to download again\")\n",
    "                    print(\"=\"*60)\n",
    "                    raise ValueError(f\"Rate limited by Yahoo Finance. Please wait 15-20 minutes and try again.\")\n",
    "            else:\n",
    "                # For other errors, raise immediately\n",
    "                print(f\"Error: {e}\")\n",
    "                raise\n",
    "\n",
    "# If still no data and USE_SAMPLE_DATA is True, generate sample data\n",
    "if (data is None or data.empty) and USE_SAMPLE_DATA:\n",
    "    print(\"\\n⚠️  Using sample data (USE_SAMPLE_DATA=True)\")\n",
    "    print(\"This is synthetic data for testing purposes only!\")\n",
    "    \n",
    "    # Generate sample OHLC data\n",
    "    dates = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
    "    dates = dates[dates.weekday < 5]  # Only weekdays\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_days = len(dates)\n",
    "    base_price = 400.0\n",
    "    \n",
    "    # Generate realistic price movements\n",
    "    returns = np.random.normal(0.0005, 0.015, n_days)  # Daily returns\n",
    "    prices = base_price * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # Generate OHLC from close prices\n",
    "    data = pd.DataFrame({\n",
    "        'Open': prices * (1 + np.random.normal(0, 0.002, n_days)),\n",
    "        'High': prices * (1 + np.abs(np.random.normal(0, 0.005, n_days))),\n",
    "        'Low': prices * (1 - np.abs(np.random.normal(0, 0.005, n_days))),\n",
    "        'Close': prices,\n",
    "        'Volume': np.random.randint(50000000, 200000000, n_days)\n",
    "    }, index=dates)\n",
    "    \n",
    "    # Ensure High >= Close >= Low and High >= Open >= Low\n",
    "    data['High'] = data[['Open', 'High', 'Close']].max(axis=1) * 1.001\n",
    "    data['Low'] = data[['Open', 'Low', 'Close']].min(axis=1) * 0.999\n",
    "    \n",
    "    print(f\"✓ Generated {len(data)} days of sample data\")\n",
    "    print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "    print(f\"\\n⚠️  WARNING: This is synthetic data, not real market data!\")\n",
    "    print(f\"   Set USE_SAMPLE_DATA=False and wait 15-20 minutes to download real data.\")\n",
    "\n",
    "# Display data info\n",
    "if data is not None and not data.empty:\n",
    "    print(f\"\\n✓ Successfully loaded {len(data)} days of data\")\n",
    "    print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "    print(f\"\\nData preview:\")\n",
    "    display(data.head())  # Use display() to ensure it shows in Jupyter\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NO DATA AVAILABLE - OPTIONS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"1. Wait 15-20 minutes, then run this cell again\")\n",
    "    print(\"2. Set USE_SAMPLE_DATA = True at the top of this cell to use sample data\")\n",
    "    print(\"   (for testing purposes only - not real market data)\")\n",
    "    print(\"3. Try again later today (rate limits reset over time)\")\n",
    "    print(\"=\"*70)\n",
    "    raise ValueError(\"No data available. Set USE_SAMPLE_DATA=True to continue with sample data, or wait and try downloading again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n",
      "\n",
      "Features shape: (986, 6)\n",
      "Target distribution:\n",
      "target\n",
      "1    528\n",
      "0    458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns: ['return_1d', 'return_5d', 'volatility_20d', 'ma_5d', 'ma_20d', 'ma_gap']\n"
     ]
    }
   ],
   "source": [
    "# Engineer features\n",
    "print(\"Engineering features...\")\n",
    "data_features = engineer_features(\n",
    "    data,\n",
    "    return_periods=[1, 5],\n",
    "    volatility_window=20,\n",
    "    ma_windows=[5, 20]\n",
    ")\n",
    "\n",
    "# Prepare features for training\n",
    "X, y = prepare_features_for_training(data_features)\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split (Time Series Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 690 samples\n",
      "Validation set: 148 samples\n",
      "Test set: 148 samples\n"
     ]
    }
   ],
   "source": [
    "# Combine X and y for time series split\n",
    "data_combined = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Split data\n",
    "train, val, test = time_series_split(data_combined, train_size=0.7, val_size=0.15)\n",
    "\n",
    "X_train = train[X.columns]\n",
    "y_train = train['target']\n",
    "X_val = val[X.columns]\n",
    "y_val = val['target']\n",
    "X_test = test[X.columns]\n",
    "y_test = test['target']\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "Validation Metrics:\n",
      "  AUC: 0.5410\n",
      "  Train Accuracy: 0.9681\n",
      "  Validation Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Choose model: 'random_forest' or 'xgboost'\n",
    "MODEL_TYPE = 'random_forest'  # Change to 'xgboost' to use XGBoost\n",
    "\n",
    "if MODEL_TYPE == 'random_forest':\n",
    "    print(\"Training Random Forest...\")\n",
    "    model, metrics = train_random_forest(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "elif MODEL_TYPE == 'xgboost':\n",
    "    print(\"Training XGBoost...\")\n",
    "    model, metrics = train_xgboost(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"  Train Accuracy: {metrics['train_accuracy']:.4f}\")\n",
    "print(f\"  Validation Accuracy: {metrics['val_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "          feature  importance\n",
      "0       return_1d    0.189799\n",
      "2  volatility_20d    0.170683\n",
      "1       return_5d    0.169874\n",
      "3           ma_5d    0.164021\n",
      "5          ma_gap    0.159691\n",
      "4          ma_20d    0.145932\n",
      "Feature importance plot saved to c:\\Users\\Admin\\Documents\\Projects\\ml-signal-generator\\outputs\\feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance_df = get_feature_importance(model, list(X.columns))\n",
    "print(\"Feature Importance:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "# Ensure output_dir is defined (from Cell 1)\n",
    "if 'output_dir' not in globals():\n",
    "    from pathlib import Path\n",
    "    output_dir = Path('outputs')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "feature_importance_path = str(output_dir / 'feature_importance.png')\n",
    "plot_feature_importance(importance_df, feature_importance_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "  AUC: 0.5455\n",
      "  Accuracy: 0.5608\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.21      0.29        63\n",
      "           1       0.58      0.82      0.68        85\n",
      "\n",
      "    accuracy                           0.56       148\n",
      "   macro avg       0.52      0.51      0.48       148\n",
      "weighted avg       0.53      0.56      0.51       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_results = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  AUC: {test_results['auc']:.4f}\")\n",
    "print(f\"  Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_results['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Statistics:\n",
      "  Total signals: 104 out of 147 days\n",
      "  Signal rate: 70.75%\n",
      "\n",
      "Test returns range: 2023-05-31 00:00:00 to 2023-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Generate signals on test set\n",
    "SIGNAL_THRESHOLD = 0.55  # Probability threshold for signal generation\n",
    "\n",
    "# Create signals as Series with X_test index for proper alignment\n",
    "signals = pd.Series(\n",
    "    generate_signals(test_results['y_pred_proba'], threshold=SIGNAL_THRESHOLD),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Get actual returns for backtesting\n",
    "test_returns = data_features.loc[X_test.index, 'next_return'].dropna()\n",
    "\n",
    "# Align signals with test_returns (remove rows where returns are NaN)\n",
    "signals = signals.loc[test_returns.index]\n",
    "\n",
    "print(f\"Signal Statistics:\")\n",
    "print(f\"  Total signals: {signals.sum()} out of {len(signals)} days\")\n",
    "print(f\"  Signal rate: {signals.mean()*100:.2f}%\")\n",
    "print(f\"\\nTest returns range: {test_returns.index[0]} to {test_returns.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Backtest Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backtest Performance Metrics:\n",
      "  Total Return: 13.82%\n",
      "  Annualized Return: 24.85%\n",
      "  Volatility: 9.58%\n",
      "  Sharpe Ratio: 2.59\n",
      "  Max Drawdown: -7.77%\n",
      "  Win Rate: 61.17%\n",
      "  Total Trades: 104\n"
     ]
    }
   ],
   "source": [
    "# Align signals with returns (already aligned in previous cell)\n",
    "aligned_data = pd.DataFrame({\n",
    "    'signals': signals.values,\n",
    "    'returns': test_returns.values\n",
    "}, index=signals.index)\n",
    "\n",
    "# Backtest\n",
    "equity, metrics = backtest_strategy(\n",
    "    aligned_data['signals'].values,\n",
    "    aligned_data['returns'].values,\n",
    "    initial_capital=10000.0\n",
    ")\n",
    "\n",
    "# Create equity series with dates\n",
    "# Handle both Series and array returns from backtest_strategy\n",
    "if isinstance(equity, pd.Series):\n",
    "    equity_series = equity.reindex(aligned_data.index)\n",
    "else:\n",
    "    equity_series = pd.Series(equity, index=aligned_data.index)\n",
    "\n",
    "print(\"\\nBacktest Performance Metrics:\")\n",
    "print(f\"  Total Return: {metrics['total_return_pct']:.2f}%\")\n",
    "print(f\"  Annualized Return: {metrics['annualized_return_pct']:.2f}%\")\n",
    "print(f\"  Volatility: {metrics['volatility_pct']:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"  Max Drawdown: {metrics['max_drawdown_pct']:.2f}%\")\n",
    "print(f\"  Win Rate: {metrics['win_rate_pct']:.2f}%\")\n",
    "print(f\"  Total Trades: {metrics['total_trades']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equity curve saved to c:\\Users\\Admin\\Documents\\Projects\\ml-signal-generator\\outputs\\equity_curve.png\n"
     ]
    }
   ],
   "source": [
    "# Plot equity curve\n",
    "# Ensure output_dir is defined (from Cell 1)\n",
    "if 'output_dir' not in globals():\n",
    "    from pathlib import Path\n",
    "    output_dir = Path('outputs')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "equity_curve_path = str(output_dir / 'equity_curve.png')\n",
    "plot_equity_curve(equity_series, equity_curve_path, 'Strategy Equity Curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
