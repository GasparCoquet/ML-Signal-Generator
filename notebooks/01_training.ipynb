{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Signal Generator - Training Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline for:\n",
    "1. Downloading market data\n",
    "2. Engineering features\n",
    "3. Training ML models\n",
    "4. Generating trading signals\n",
    "5. Backtesting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from features import download_data, engineer_features, prepare_features_for_training\n",
    "from model import time_series_split, train_random_forest, train_xgboost, get_feature_importance, evaluate_model\n",
    "from backtest import generate_signals, backtest_strategy, plot_equity_curve, plot_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for SPY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaspa\\Documents\\ml-signal-generator\\src\\features.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1006 days of data\n",
      "Date range: 2020-01-02 00:00:00 to 2023-12-29 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>298.578644</td>\n",
       "      <td>298.597043</td>\n",
       "      <td>296.428021</td>\n",
       "      <td>297.356291</td>\n",
       "      <td>59151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>296.317749</td>\n",
       "      <td>297.448217</td>\n",
       "      <td>295.113768</td>\n",
       "      <td>295.168910</td>\n",
       "      <td>77709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>297.448242</td>\n",
       "      <td>297.530955</td>\n",
       "      <td>294.433661</td>\n",
       "      <td>294.553145</td>\n",
       "      <td>55653900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>296.611908</td>\n",
       "      <td>297.356354</td>\n",
       "      <td>296.161544</td>\n",
       "      <td>296.878418</td>\n",
       "      <td>40496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>298.192719</td>\n",
       "      <td>299.415071</td>\n",
       "      <td>296.556773</td>\n",
       "      <td>296.804912</td>\n",
       "      <td>68296000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close        High         Low        Open    Volume\n",
       "Date                                                                \n",
       "2020-01-02  298.578644  298.597043  296.428021  297.356291  59151200\n",
       "2020-01-03  296.317749  297.448217  295.113768  295.168910  77709700\n",
       "2020-01-06  297.448242  297.530955  294.433661  294.553145  55653900\n",
       "2020-01-07  296.611908  297.356354  296.161544  296.878418  40496400\n",
       "2020-01-08  298.192719  299.415071  296.556773  296.804912  68296000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "TICKER = 'SPY'  # S&P 500 ETF\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2024-01-01'\n",
    "\n",
    "# Download OHLC data\n",
    "print(f\"Downloading data for {TICKER}...\")\n",
    "data = download_data(TICKER, START_DATE, END_DATE)\n",
    "print(f\"Downloaded {len(data)} days of data\")\n",
    "print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n",
      "\n",
      "Features shape: (986, 6)\n",
      "Target distribution:\n",
      "target\n",
      "1    529\n",
      "0    457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns: ['return_1d', 'return_5d', 'volatility_20d', 'ma_5d', 'ma_20d', 'ma_gap']\n"
     ]
    }
   ],
   "source": [
    "# Engineer features\n",
    "print(\"Engineering features...\")\n",
    "data_features = engineer_features(\n",
    "    data,\n",
    "    return_periods=[1, 5],\n",
    "    volatility_window=20,\n",
    "    ma_windows=[5, 20]\n",
    ")\n",
    "\n",
    "# Prepare features for training\n",
    "X, y = prepare_features_for_training(data_features)\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split (Time Series Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 690 samples\n",
      "Validation set: 148 samples\n",
      "Test set: 148 samples\n"
     ]
    }
   ],
   "source": [
    "# Combine X and y for time series split\n",
    "data_combined = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Split data\n",
    "train, val, test = time_series_split(data_combined, train_size=0.7, val_size=0.15)\n",
    "\n",
    "X_train = train[X.columns]\n",
    "y_train = train['target']\n",
    "X_val = val[X.columns]\n",
    "y_val = val['target']\n",
    "X_test = test[X.columns]\n",
    "y_test = test['target']\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "Validation Metrics:\n",
      "  AUC: 0.5417\n",
      "  Train Accuracy: 0.9725\n",
      "  Validation Accuracy: 0.5473\n"
     ]
    }
   ],
   "source": [
    "# Choose model: 'random_forest' or 'xgboost'\n",
    "MODEL_TYPE = 'random_forest'  # Change to 'xgboost' to use XGBoost\n",
    "\n",
    "if MODEL_TYPE == 'random_forest':\n",
    "    print(\"Training Random Forest...\")\n",
    "    model, metrics = train_random_forest(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "elif MODEL_TYPE == 'xgboost':\n",
    "    print(\"Training XGBoost...\")\n",
    "    model, metrics = train_xgboost(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"  Train Accuracy: {metrics['train_accuracy']:.4f}\")\n",
    "print(f\"  Validation Accuracy: {metrics['val_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "          feature  importance\n",
      "0       return_1d    0.184821\n",
      "2  volatility_20d    0.170873\n",
      "1       return_5d    0.168280\n",
      "4          ma_20d    0.160028\n",
      "5          ma_gap    0.158587\n",
      "3           ma_5d    0.157412\n",
      "Feature importance plot saved to outputs/feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance_df = get_feature_importance(model, list(X.columns))\n",
    "print(\"Feature Importance:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plot_feature_importance(importance_df, 'outputs/feature_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "  AUC: 0.4665\n",
      "  Accuracy: 0.5135\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20        63\n",
      "           1       0.55      0.79      0.65        85\n",
      "\n",
      "    accuracy                           0.51       148\n",
      "   macro avg       0.44      0.47      0.43       148\n",
      "weighted avg       0.46      0.51      0.46       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_results = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  AUC: {test_results['auc']:.4f}\")\n",
    "print(f\"  Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_results['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Statistics:\n",
      "  Total signals: 99 out of 148 days\n",
      "  Signal rate: 66.89%\n",
      "\n",
      "Test returns range: 2023-05-31 00:00:00 to 2023-12-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Generate signals on test set\n",
    "SIGNAL_THRESHOLD = 0.55  # Probability threshold for signal generation\n",
    "\n",
    "# Create signals as Series with X_test index for proper alignment\n",
    "signals = pd.Series(\n",
    "    generate_signals(test_results['y_pred_proba'], threshold=SIGNAL_THRESHOLD),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Get actual returns for backtesting\n",
    "test_returns = data_features.loc[X_test.index, 'next_return'].dropna()\n",
    "\n",
    "# Align signals with test_returns (remove rows where returns are NaN)\n",
    "signals = signals.loc[test_returns.index]\n",
    "\n",
    "print(f\"Signal Statistics:\")\n",
    "print(f\"  Total signals: {signals.sum()} out of {len(signals)} days\")\n",
    "print(f\"  Signal rate: {signals.mean()*100:.2f}%\")\n",
    "print(f\"\\nTest returns range: {test_returns.index[0]} to {test_returns.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Backtest Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 148 does not match index length 147",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Align signals with returns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m aligned_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msignals\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msignals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturns\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_returns\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.dropna()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Backtest\u001b[39;00m\n\u001b[32m      8\u001b[39m equity, metrics = backtest_strategy(\n\u001b[32m      9\u001b[39m     aligned_data[\u001b[33m'\u001b[39m\u001b[33msignals\u001b[39m\u001b[33m'\u001b[39m].values,\n\u001b[32m     10\u001b[39m     aligned_data[\u001b[33m'\u001b[39m\u001b[33mreturns\u001b[39m\u001b[33m'\u001b[39m].values,\n\u001b[32m     11\u001b[39m     initial_capital=\u001b[32m10000.0\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaspa\\Documents\\ml-signal-generator\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaspa\\Documents\\ml-signal-generator\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaspa\\Documents\\ml-signal-generator\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaspa\\Documents\\ml-signal-generator\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:690\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[32m0\u001b[39m] != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m    686\u001b[39m         msg = (\n\u001b[32m    687\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not match index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    688\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    692\u001b[39m     index = default_index(lengths[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: array length 148 does not match index length 147"
     ]
    }
   ],
   "source": [
    "# Align signals with returns (already aligned in previous cell)\n",
    "aligned_data = pd.DataFrame({\n",
    "    'signals': signals.values,\n",
    "    'returns': test_returns.values\n",
    "}, index=signals.index)\n",
    "\n",
    "# Backtest\n",
    "equity, metrics = backtest_strategy(\n",
    "    aligned_data['signals'].values,\n",
    "    aligned_data['returns'].values,\n",
    "    initial_capital=10000.0\n",
    ")\n",
    "\n",
    "# Create equity series with dates\n",
    "# Handle both Series and array returns from backtest_strategy\n",
    "if isinstance(equity, pd.Series):\n",
    "    equity_series = equity.reindex(aligned_data.index)\n",
    "else:\n",
    "    equity_series = pd.Series(equity, index=aligned_data.index)\n",
    "\n",
    "print(\"\\nBacktest Performance Metrics:\")\n",
    "print(f\"  Total Return: {metrics['total_return_pct']:.2f}%\")\n",
    "print(f\"  Annualized Return: {metrics['annualized_return_pct']:.2f}%\")\n",
    "print(f\"  Volatility: {metrics['volatility_pct']:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"  Max Drawdown: {metrics['max_drawdown_pct']:.2f}%\")\n",
    "print(f\"  Win Rate: {metrics['win_rate_pct']:.2f}%\")\n",
    "print(f\"  Total Trades: {metrics['total_trades']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "plot_equity_curve(equity_series, 'outputs/equity_curve.png', 'Strategy Equity Curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
